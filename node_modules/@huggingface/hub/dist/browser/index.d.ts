declare const PIPELINE_DATA: {
    "text-classification": {
        name: string;
        subtasks: {
            type: string;
            name: string;
        }[];
        modality: "nlp";
        color: "orange";
    };
    "token-classification": {
        name: string;
        subtasks: {
            type: string;
            name: string;
        }[];
        modality: "nlp";
        color: "blue";
    };
    "table-question-answering": {
        name: string;
        modality: "nlp";
        color: "green";
    };
    "question-answering": {
        name: string;
        subtasks: {
            type: string;
            name: string;
        }[];
        modality: "nlp";
        color: "blue";
    };
    "zero-shot-classification": {
        name: string;
        modality: "nlp";
        color: "yellow";
    };
    translation: {
        name: string;
        modality: "nlp";
        color: "green";
    };
    summarization: {
        name: string;
        subtasks: {
            type: string;
            name: string;
        }[];
        modality: "nlp";
        color: "indigo";
    };
    "feature-extraction": {
        name: string;
        modality: "nlp";
        color: "red";
    };
    "text-generation": {
        name: string;
        subtasks: {
            type: string;
            name: string;
        }[];
        modality: "nlp";
        color: "indigo";
    };
    "text2text-generation": {
        name: string;
        subtasks: {
            type: string;
            name: string;
        }[];
        modality: "nlp";
        color: "indigo";
    };
    "fill-mask": {
        name: string;
        subtasks: {
            type: string;
            name: string;
        }[];
        modality: "nlp";
        color: "red";
    };
    "sentence-similarity": {
        name: string;
        modality: "nlp";
        color: "yellow";
    };
    "text-to-speech": {
        name: string;
        modality: "audio";
        color: "yellow";
    };
    "text-to-audio": {
        name: string;
        modality: "audio";
        color: "yellow";
    };
    "automatic-speech-recognition": {
        name: string;
        modality: "audio";
        color: "yellow";
    };
    "audio-to-audio": {
        name: string;
        modality: "audio";
        color: "blue";
    };
    "audio-classification": {
        name: string;
        subtasks: {
            type: string;
            name: string;
        }[];
        modality: "audio";
        color: "green";
    };
    "voice-activity-detection": {
        name: string;
        modality: "audio";
        color: "red";
    };
    "depth-estimation": {
        name: string;
        modality: "cv";
        color: "yellow";
    };
    "image-classification": {
        name: string;
        subtasks: {
            type: string;
            name: string;
        }[];
        modality: "cv";
        color: "blue";
    };
    "object-detection": {
        name: string;
        subtasks: {
            type: string;
            name: string;
        }[];
        modality: "cv";
        color: "yellow";
    };
    "image-segmentation": {
        name: string;
        subtasks: {
            type: string;
            name: string;
        }[];
        modality: "cv";
        color: "green";
    };
    "text-to-image": {
        name: string;
        modality: "cv";
        color: "yellow";
    };
    "image-to-text": {
        name: string;
        subtasks: {
            type: string;
            name: string;
        }[];
        modality: "cv";
        color: "red";
    };
    "image-to-image": {
        name: string;
        subtasks: {
            type: string;
            name: string;
        }[];
        modality: "cv";
        color: "indigo";
    };
    "image-to-video": {
        name: string;
        modality: "cv";
        color: "indigo";
    };
    "unconditional-image-generation": {
        name: string;
        modality: "cv";
        color: "green";
    };
    "video-classification": {
        name: string;
        modality: "cv";
        color: "blue";
    };
    "reinforcement-learning": {
        name: string;
        modality: "rl";
        color: "red";
    };
    robotics: {
        name: string;
        modality: "rl";
        subtasks: {
            type: string;
            name: string;
        }[];
        color: "blue";
    };
    "tabular-classification": {
        name: string;
        modality: "tabular";
        subtasks: {
            type: string;
            name: string;
        }[];
        color: "blue";
    };
    "tabular-regression": {
        name: string;
        modality: "tabular";
        subtasks: {
            type: string;
            name: string;
        }[];
        color: "blue";
    };
    "tabular-to-text": {
        name: string;
        modality: "tabular";
        subtasks: {
            type: string;
            name: string;
        }[];
        color: "blue";
        hideInModels: true;
    };
    "table-to-text": {
        name: string;
        modality: "nlp";
        color: "blue";
        hideInModels: true;
    };
    "multiple-choice": {
        name: string;
        subtasks: {
            type: string;
            name: string;
        }[];
        modality: "nlp";
        color: "blue";
        hideInModels: true;
    };
    "text-retrieval": {
        name: string;
        subtasks: {
            type: string;
            name: string;
        }[];
        modality: "nlp";
        color: "indigo";
        hideInModels: true;
    };
    "time-series-forecasting": {
        name: string;
        modality: "tabular";
        subtasks: {
            type: string;
            name: string;
        }[];
        color: "blue";
        hideInModels: true;
    };
    "text-to-video": {
        name: string;
        modality: "cv";
        color: "green";
    };
    "image-text-to-text": {
        name: string;
        modality: "multimodal";
        color: "red";
        hideInDatasets: true;
    };
    "visual-question-answering": {
        name: string;
        subtasks: {
            type: string;
            name: string;
        }[];
        modality: "multimodal";
        color: "red";
    };
    "document-question-answering": {
        name: string;
        subtasks: {
            type: string;
            name: string;
        }[];
        modality: "multimodal";
        color: "blue";
        hideInDatasets: true;
    };
    "zero-shot-image-classification": {
        name: string;
        modality: "cv";
        color: "yellow";
    };
    "graph-ml": {
        name: string;
        modality: "other";
        color: "green";
    };
    "mask-generation": {
        name: string;
        modality: "cv";
        color: "indigo";
    };
    "zero-shot-object-detection": {
        name: string;
        modality: "cv";
        color: "yellow";
    };
    "text-to-3d": {
        name: string;
        modality: "cv";
        color: "yellow";
    };
    "image-to-3d": {
        name: string;
        modality: "cv";
        color: "green";
    };
    "image-feature-extraction": {
        name: string;
        modality: "cv";
        color: "indigo";
    };
    other: {
        name: string;
        modality: "other";
        color: "blue";
        hideInModels: true;
        hideInDatasets: true;
    };
};
type PipelineType = keyof typeof PIPELINE_DATA;

/**
 * See default-widget-inputs.ts for the default widget inputs, this files only contains the types
 */
type TableData = Record<string, (string | number)[]>;
type WidgetExampleOutputLabels = Array<{
    label: string;
    score: number;
}>;
interface WidgetExampleOutputAnswerScore {
    answer: string;
    score: number;
}
interface WidgetExampleOutputText {
    text: string;
}
interface WidgetExampleOutputUrl {
    url: string;
}
type WidgetExampleOutput = WidgetExampleOutputLabels | WidgetExampleOutputAnswerScore | WidgetExampleOutputText | WidgetExampleOutputUrl;
interface WidgetExampleBase<TOutput> {
    example_title?: string;
    group?: string;
    /**
     * Potential overrides to API parameters for this specific example
     * (takes precedences over the model card metadata's inference.parameters)
     */
    parameters?: {
        aggregation_strategy?: string;
        top_k?: number;
        top_p?: number;
        temperature?: number;
        max_new_tokens?: number;
        do_sample?: boolean;
        negative_prompt?: string;
        guidance_scale?: number;
        num_inference_steps?: number;
    };
    /**
     * Optional output
     */
    output?: TOutput;
}
interface ChatMessage {
    role: "user" | "assistant" | "system";
    content: string;
}
interface WidgetExampleChatInput<TOutput = WidgetExampleOutput> extends WidgetExampleBase<TOutput> {
    messages: ChatMessage[];
}
interface WidgetExampleTextInput<TOutput = WidgetExampleOutput> extends WidgetExampleBase<TOutput> {
    text: string;
}
interface WidgetExampleTextAndContextInput<TOutput = WidgetExampleOutput> extends WidgetExampleTextInput<TOutput> {
    context: string;
}
interface WidgetExampleTextAndTableInput<TOutput = WidgetExampleOutput> extends WidgetExampleTextInput<TOutput> {
    table: TableData;
}
interface WidgetExampleAssetInput<TOutput = WidgetExampleOutput> extends WidgetExampleBase<TOutput> {
    src: string;
}
interface WidgetExampleAssetAndPromptInput<TOutput = WidgetExampleOutput> extends WidgetExampleAssetInput<TOutput> {
    prompt: string;
}
type WidgetExampleAssetAndTextInput<TOutput = WidgetExampleOutput> = WidgetExampleAssetInput<TOutput> & WidgetExampleTextInput<TOutput>;
type WidgetExampleAssetAndZeroShotInput<TOutput = WidgetExampleOutput> = WidgetExampleAssetInput<TOutput> & WidgetExampleZeroShotTextInput<TOutput>;
interface WidgetExampleStructuredDataInput<TOutput = WidgetExampleOutput> extends WidgetExampleBase<TOutput> {
    structured_data: TableData;
}
interface WidgetExampleTableDataInput<TOutput = WidgetExampleOutput> extends WidgetExampleBase<TOutput> {
    table: TableData;
}
interface WidgetExampleZeroShotTextInput<TOutput = WidgetExampleOutput> extends WidgetExampleTextInput<TOutput> {
    text: string;
    candidate_labels: string;
    multi_class: boolean;
}
interface WidgetExampleSentenceSimilarityInput<TOutput = WidgetExampleOutput> extends WidgetExampleBase<TOutput> {
    source_sentence: string;
    sentences: string[];
}
type WidgetExample<TOutput = WidgetExampleOutput> = WidgetExampleChatInput<TOutput> | WidgetExampleTextInput<TOutput> | WidgetExampleTextAndContextInput<TOutput> | WidgetExampleTextAndTableInput<TOutput> | WidgetExampleAssetInput<TOutput> | WidgetExampleAssetAndPromptInput<TOutput> | WidgetExampleAssetAndTextInput<TOutput> | WidgetExampleAssetAndZeroShotInput<TOutput> | WidgetExampleStructuredDataInput<TOutput> | WidgetExampleTableDataInput<TOutput> | WidgetExampleZeroShotTextInput<TOutput> | WidgetExampleSentenceSimilarityInput<TOutput>;

declare const SPECIAL_TOKENS_ATTRIBUTES: readonly ["bos_token", "eos_token", "unk_token", "sep_token", "pad_token", "cls_token", "mask_token"];
/**
 * Public interface for a tokenizer's special tokens mapping
 */
interface AddedToken {
    __type: "AddedToken";
    content?: string;
    lstrip?: boolean;
    normalized?: boolean;
    rstrip?: boolean;
    single_word?: boolean;
}
type SpecialTokensMap = {
    [key in (typeof SPECIAL_TOKENS_ATTRIBUTES)[number]]?: string | AddedToken | null;
};
/**
 * Public interface for tokenizer config
 */
interface TokenizerConfig extends SpecialTokensMap {
    use_default_system_prompt?: boolean;
    chat_template?: string | Array<{
        name: string;
        template: string;
    }>;
}

declare enum InferenceDisplayability {
    /**
     * Yes
     */
    Yes = "Yes",
    /**
     * And then, all the possible reasons why it's no:
     */
    ExplicitOptOut = "ExplicitOptOut",
    CustomCode = "CustomCode",
    LibraryNotDetected = "LibraryNotDetected",
    PipelineNotDetected = "PipelineNotDetected",
    PipelineLibraryPairNotSupported = "PipelineLibraryPairNotSupported"
}
/**
 * Public interface for model metadata
 */
interface ModelData {
    /**
     * id of model (e.g. 'user/repo_name')
     */
    id: string;
    /**
     * Kept for backward compatibility
     */
    modelId?: string;
    /**
     * Whether or not to enable inference widget for this model
     */
    inference: InferenceDisplayability;
    /**
     * is this model private?
     */
    private?: boolean;
    /**
     * this dictionary has useful information about the model configuration
     */
    config?: {
        architectures?: string[];
        /**
         * Dict of AutoModel or Auto… class name to local import path in the repo
         */
        auto_map?: {
            /**
             * String Property
             */
            [x: string]: string;
        };
        model_type?: string;
        quantization_config?: {
            bits?: number;
            load_in_4bit?: boolean;
            load_in_8bit?: boolean;
        };
        tokenizer_config?: TokenizerConfig;
        adapter_transformers?: {
            model_name?: string;
            model_class?: string;
        };
        diffusers?: {
            _class_name?: string;
        };
        sklearn?: {
            model?: {
                file?: string;
            };
            model_format?: string;
        };
        speechbrain?: {
            speechbrain_interface?: string;
            vocoder_interface?: string;
            vocoder_model_id?: string;
        };
        peft?: {
            base_model_name_or_path?: string;
            task_type?: string;
        };
    };
    /**
     * all the model tags
     */
    tags?: string[];
    /**
     * transformers-specific info to display in the code sample.
     */
    transformersInfo?: TransformersInfo;
    /**
     * Pipeline type
     */
    pipeline_tag?: PipelineType | undefined;
    /**
     * for relevant models, get mask token
     */
    mask_token?: string | undefined;
    /**
     * Example data that will be fed into the widget.
     *
     * can be set in the model card metadata (under `widget`),
     * or by default in `DefaultWidget.ts`
     */
    widgetData?: WidgetExample[] | undefined;
    /**
     * Parameters that will be used by the widget when calling Inference API (serverless)
     * https://huggingface.co/docs/api-inference/detailed_parameters
     *
     * can be set in the model card metadata (under `inference/parameters`)
     * Example:
     * inference:
     *     parameters:
     *         key: val
     */
    cardData?: {
        inference?: boolean | {
            parameters?: Record<string, unknown>;
        };
        base_model?: string | string[];
    };
    /**
     * Library name
     * Example: transformers, SpeechBrain, Stanza, etc.
     */
    library_name?: string;
}
/**
 * transformers-specific info to display in the code sample.
 */
interface TransformersInfo {
    /**
     * e.g. AutoModelForSequenceClassification
     */
    auto_model: string;
    /**
     * if set in config.json's auto_map
     */
    custom_class?: string;
    /**
     * e.g. text-classification
     */
    pipeline_tag?: PipelineType;
    /**
     * e.g. "AutoTokenizer" | "AutoFeatureExtractor" | "AutoProcessor"
     */
    processor?: string;
}
/**
 * Add your new library here.
 *
 * This is for modeling (= architectures) libraries, not for file formats (like ONNX, etc).
 * (unlike libraries, file formats live in an enum inside the internal codebase.)
 *
 * Doc on how to add a library to the Hub:
 *
 * https://huggingface.co/docs/hub/models-adding-libraries
 *
 * /!\ IMPORTANT
 *
 * The key you choose is the tag your models have in their library_name on the Hub.
 */
declare const MODEL_LIBRARIES_UI_ELEMENTS: {
    "adapter-transformers": {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        docsUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
        countDownloads: {
            term: {
                path: string;
            };
        };
    };
    allennlp: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        docsUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
    };
    asteroid: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        docsUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
        countDownloads: {
            term: {
                path: string;
            };
        };
    };
    audiocraft: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        snippets: (model: ModelData) => string[];
        filter: false;
    };
    bertopic: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
    };
    diffusers: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        docsUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
    };
    doctr: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
    };
    elm: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        filter: false;
        countDownloads: {
            wildcard: {
                path: string;
            };
        };
    };
    espnet: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        docsUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
    };
    fairseq: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
    };
    fastai: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        docsUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
    };
    fasttext: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
    };
    flair: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        docsUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
        countDownloads: {
            term: {
                path: string;
            };
        };
    };
    gliner: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        snippets: (model: ModelData) => string[];
        filter: false;
        countDownloads: {
            term: {
                path: string;
            };
        };
    };
    grok: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        filter: false;
        countDownloads: {
            terms: {
                path: string[];
            };
        };
    };
    keras: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        docsUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
        countDownloads: {
            term: {
                path: string;
            };
        };
    };
    "keras-nlp": {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        docsUrl: string;
        snippets: (model: ModelData) => string[];
    };
    k2: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
    };
    mindspore: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
    };
    "ml-agents": {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        docsUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
        countDownloads: {
            wildcard: {
                path: string;
            };
        };
    };
    mlx: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
    };
    "mlx-image": {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        docsUrl: string;
        snippets: (model: ModelData) => string[];
        filter: false;
        countDownloads: {
            term: {
                path: string;
            };
        };
    };
    nemo: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
        countDownloads: {
            wildcard: {
                path: string;
            };
        };
    };
    open_clip: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
        countDownloads: {
            wildcard: {
                path: string;
            };
        };
    };
    paddlenlp: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        docsUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
        countDownloads: {
            term: {
                path: string;
            };
        };
    };
    peft: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
        countDownloads: {
            term: {
                path: string;
            };
        };
    };
    "pyannote-audio": {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
    };
    pythae: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
    };
    "sample-factory": {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        docsUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
        countDownloads: {
            term: {
                path: string;
            };
        };
    };
    "sentence-transformers": {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        docsUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
    };
    setfit: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        docsUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
    };
    sklearn: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
        countDownloads: {
            term: {
                path: string;
            };
        };
    };
    spacy: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        docsUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
        countDownloads: {
            wildcard: {
                path: string;
            };
        };
    };
    "span-marker": {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        docsUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
    };
    speechbrain: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        docsUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
        countDownloads: {
            term: {
                path: string;
            };
        };
    };
    "stable-baselines3": {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        docsUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
        countDownloads: {
            wildcard: {
                path: string;
            };
        };
    };
    stanza: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        docsUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
        countDownloads: {
            term: {
                path: string;
            };
        };
    };
    tensorflowtts: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        snippets: (model: ModelData) => string[];
    };
    timm: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        docsUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
        countDownloads: {
            terms: {
                path: string[];
            };
        };
    };
    transformers: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        docsUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
    };
    "transformers.js": {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        docsUrl: string;
        snippets: (model: ModelData) => string[];
        filter: true;
    };
    "unity-sentis": {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        snippets: () => string[];
        filter: true;
        countDownloads: {
            wildcard: {
                path: string;
            };
        };
    };
    voicecraft: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        docsUrl: string;
        snippets: (model: ModelData) => string[];
    };
    whisperkit: {
        prettyLabel: string;
        repoName: string;
        repoUrl: string;
        countDownloads: {
            wildcard: {
                path: string;
            };
        };
    };
};
type ModelLibraryKey = keyof typeof MODEL_LIBRARIES_UI_ELEMENTS;

type RepoType = "space" | "dataset" | "model";

interface RepoId {
	name: string;
	type: RepoType;
}

type RepoFullName = string | `spaces/${string}` | `datasets/${string}`;

type RepoDesignation = RepoId | RepoFullName;

/** Actually `hf_${string}`, but for convenience, using the string type */
type AccessToken = string;

interface Credentials {
	accessToken: AccessToken;
}

type SpaceHardwareFlavor =
	| "cpu-basic"
	| "cpu-upgrade"
	| "t4-small"
	| "t4-medium"
	| "a10g-small"
	| "a10g-large"
	| "a100-large";

type SpaceSdk = "streamlit" | "gradio" | "docker" | "static";

type SpaceStage =
	| "NO_APP_FILE"
	| "CONFIG_ERROR"
	| "BUILDING"
	| "BUILD_ERROR"
	| "RUNNING"
	| "RUNNING_BUILDING"
	| "RUNTIME_ERROR"
	| "DELETING"
	| "PAUSED"
	| "SLEEPING";

type AccessTokenRole = "admin" | "write" | "contributor" | "read";

type AuthType = "access_token" | "app_token" | "app_token_as_user";


interface SpaceRuntime {
	stage: SpaceStage;
	sdk?: SpaceSdk;
	sdkVersion?: string;
	errorMessage?: string;
	hardware?: {
		current: SpaceHardwareFlavor | null;
		currentPrettyName?: string;
		requested: SpaceHardwareFlavor | null;
		requestedPrettyName?: string;
	};
	/** when calling /spaces, those props are only fetched if ?full=true */
	resources?: SpaceResourceConfig;
	/** in seconds */
	gcTimeout?: number | null;
}

interface SpaceResourceRequirement {
	cpu?: string;
	memory?: string;
	gpu?: string;
	gpuModel?: string;
	ephemeral?: string;
}

interface SpaceResourceConfig {
	requests: SpaceResourceRequirement;
	limits: SpaceResourceRequirement;
	replicas?: number;
	throttled?: boolean;
	is_custom?: boolean;
}

type License =
	| "apache-2.0"
	| "mit"
	| "openrail"
	| "bigscience-openrail-m"
	| "creativeml-openrail-m"
	| "bigscience-bloom-rail-1.0"
	| "bigcode-openrail-m"
	| "afl-3.0"
	| "artistic-2.0"
	| "bsl-1.0"
	| "bsd"
	| "bsd-2-clause"
	| "bsd-3-clause"
	| "bsd-3-clause-clear"
	| "c-uda"
	| "cc"
	| "cc0-1.0"
	| "cc-by-2.0"
	| "cc-by-2.5"
	| "cc-by-3.0"
	| "cc-by-4.0"
	| "cc-by-sa-3.0"
	| "cc-by-sa-4.0"
	| "cc-by-nc-2.0"
	| "cc-by-nc-3.0"
	| "cc-by-nc-4.0"
	| "cc-by-nd-4.0"
	| "cc-by-nc-nd-3.0"
	| "cc-by-nc-nd-4.0"
	| "cc-by-nc-sa-2.0"
	| "cc-by-nc-sa-3.0"
	| "cc-by-nc-sa-4.0"
	| "cdla-sharing-1.0"
	| "cdla-permissive-1.0"
	| "cdla-permissive-2.0"
	| "wtfpl"
	| "ecl-2.0"
	| "epl-1.0"
	| "epl-2.0"
	| "etalab-2.0"
	| "eupl-1.1"
	| "agpl-3.0"
	| "gfdl"
	| "gpl"
	| "gpl-2.0"
	| "gpl-3.0"
	| "lgpl"
	| "lgpl-2.1"
	| "lgpl-3.0"
	| "isc"
	| "lppl-1.3c"
	| "ms-pl"
	| "mpl-2.0"
	| "odc-by"
	| "odbl"
	| "openrail++"
	| "osl-3.0"
	| "postgresql"
	| "ofl-1.1"
	| "ncsa"
	| "unlicense"
	| "zlib"
	| "pddl"
	| "lgpl-lr"
	| "deepfloyd-if-license"
	| "llama2"
	| "llama3"
	| "gemma"
	| "unknown"
	| "other";

interface CommitDeletedEntry {
    operation: "delete";
    path: string;
}
type ContentSource = Blob | URL;
interface CommitFile {
    operation: "addOrUpdate";
    path: string;
    content: ContentSource;
}
type CommitOperation = CommitDeletedEntry | CommitFile;
interface CommitParams {
    title: string;
    description?: string;
    repo: RepoDesignation;
    operations: CommitOperation[];
    credentials?: Credentials;
    /** @default "main" */
    branch?: string;
    /**
     * Parent commit. Optional
     *
     * - When opening a PR: will use parentCommit as the parent commit
     * - When committing on a branch: Will make sure that there were no intermediate commits
     */
    parentCommit?: string;
    isPullRequest?: boolean;
    hubUrl?: string;
    /**
     * Whether to use web workers to compute SHA256 hashes.
     *
     * We load hash-wasm from a CDN inside the web worker. Not sure how to do otherwise and still have a "clean" bundle.
     */
    useWebWorkers?: boolean | {
        minSize?: number;
        poolSize?: number;
    };
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
    abortSignal?: AbortSignal;
}
interface CommitOutput {
    pullRequestUrl?: string;
    commit: {
        oid: string;
        url: string;
    };
    hookOutput: string;
}
type CommitProgressEvent = {
    event: "phase";
    phase: "preuploading" | "uploadingLargeFiles" | "committing";
} | {
    event: "fileProgress";
    path: string;
    progress: number;
    state: "hashing" | "uploading";
};
/**
 * Internal function for now, used by commit.
 *
 * Can be exposed later to offer fine-tuned progress info
 */
declare function commitIter(params: CommitParams): AsyncGenerator<CommitProgressEvent, CommitOutput>;
declare function commit(params: CommitParams): Promise<CommitOutput>;

declare function countCommits(params: {
    credentials?: Credentials;
    repo: RepoDesignation;
    /**
     * Revision to list commits from. Defaults to the default branch.
     */
    revision?: string;
    hubUrl?: string;
    fetch?: typeof fetch;
}): Promise<number>;

declare function createRepo(params: {
    repo: RepoDesignation;
    credentials: Credentials;
    private?: boolean;
    license?: string;
    /**
     * Only a few lightweight files are supported at repo creation
     */
    files?: Array<{
        content: ArrayBuffer | Blob;
        path: string;
    }>;
    /** @required for when {@link repo.type} === "space" */
    sdk?: SpaceSdk;
    hubUrl?: string;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
}): Promise<{
    repoUrl: string;
}>;

declare function deleteFile(params: {
    credentials: Credentials;
    repo: CommitParams["repo"];
    path: string;
    commitTitle?: CommitParams["title"];
    commitDescription?: CommitParams["description"];
    hubUrl?: CommitParams["hubUrl"];
    fetch?: CommitParams["fetch"];
    branch?: CommitParams["branch"];
    isPullRequest?: CommitParams["isPullRequest"];
    parentCommit?: CommitParams["parentCommit"];
}): Promise<CommitOutput>;

declare function deleteFiles(params: {
    credentials: Credentials;
    repo: CommitParams["repo"];
    paths: string[];
    commitTitle?: CommitParams["title"];
    commitDescription?: CommitParams["description"];
    hubUrl?: CommitParams["hubUrl"];
    branch?: CommitParams["branch"];
    isPullRequest?: CommitParams["isPullRequest"];
    parentCommit?: CommitParams["parentCommit"];
    fetch?: CommitParams["fetch"];
}): Promise<CommitOutput>;

declare function deleteRepo(params: {
    repo: RepoDesignation;
    credentials: Credentials;
    hubUrl?: string;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
}): Promise<void>;

/**
 * @returns null when the file doesn't exist
 */
declare function downloadFile(params: {
    repo: RepoDesignation;
    path: string;
    /**
     * If true, will download the raw git file.
     *
     * For example, when calling on a file stored with Git LFS, the pointer file will be downloaded instead.
     */
    raw?: boolean;
    revision?: string;
    /**
     * Fetch only a specific part of the file
     */
    range?: [number, number];
    credentials?: Credentials;
    hubUrl?: string;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
}): Promise<Response | null>;

interface FileDownloadInfoOutput {
    size: number;
    etag: string;
    /**
     * In case of LFS file, link to download directly from cloud provider
     */
    downloadLink: string | null;
}
/**
 * @returns null when the file doesn't exist
 */
declare function fileDownloadInfo(params: {
    repo: RepoDesignation;
    path: string;
    revision?: string;
    credentials?: Credentials;
    hubUrl?: string;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
    /**
     * To get the raw pointer file behind a LFS file
     */
    raw?: boolean;
    /**
     * To avoid the content-disposition header in the `downloadLink` for LFS files
     *
     * So that on browsers you can use the URL in an iframe for example
     */
    noContentDisposition?: boolean;
}): Promise<FileDownloadInfoOutput | null>;

declare function fileExists(params: {
    repo: RepoDesignation;
    path: string;
    revision?: string;
    credentials?: Credentials;
    hubUrl?: string;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
}): Promise<boolean>;

interface CommitData {
    oid: string;
    title: string;
    message: string;
    authors: Array<{
        username: string;
        avatarUrl: string;
    }>;
    date: Date;
}
declare function listCommits(params: {
    credentials?: Credentials;
    repo: RepoDesignation;
    /**
     * Revision to list commits from. Defaults to the default branch.
     */
    revision?: string;
    hubUrl?: string;
    /**
     * Number of commits to fetch from the hub each http call. Defaults to 100. Can be set to 1000.
     */
    batchSize?: number;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
}): AsyncGenerator<CommitData>;

interface ApiDatasetInfo {
	_id: string;
	id: string;
	arxivIds?: string[];
	author?: string;
	cardExists?: true;
	cardError?: unknown;
	cardData?: ApiDatasetMetadata;
	contributors?: Array<{ user: string; _id: string }>;
	disabled: boolean;
	discussionsDisabled: boolean;
	gated: false | "auto" | "manual";
	gitalyUid: string;
	lastAuthor: { email: string; user?: string };
	lastModified: string; // date
	likes: number;
	likesRecent: number;
	private: boolean;
	updatedAt: string; // date
	createdAt: string; // date
	tags: string[];
	paperswithcode_id?: string;
	sha: string;
	files?: string[];
	citation?: string;
	description?: string;
	downloads: number;
	downloadsAllTime: number;
	previewable?: boolean;
	doi?: { id: string; commit: string };
}

interface ApiDatasetMetadata {
	licenses?: undefined;
	license?: License | License[];
	license_name?: string;
	license_link?: "LICENSE" | "LICENSE.md" | string;
	license_details?: string;
	languages?: undefined;
	language?: string | string[];
	language_bcp47?: string[];
	language_details?: string;
	tags?: string[];
	task_categories?: string[];
	task_ids?: string[];
	config_names?: string[];
	configs?: {
		config_name: string;
		data_files?:
			| string
			| string[]
			| {
					split: string;
					path: string | string[];
			  }[];
		data_dir?: string;
	}[];
	benchmark?: string;
	paperswithcode_id?: string | null;
	pretty_name?: string;
	viewer?: boolean;
	viewer_display_urls?: boolean;
	thumbnail?: string | null;
	description?: string | null;
	annotations_creators?: string[];
	language_creators?: string[];
	multilinguality?: string[];
	size_categories?: string[];
	source_datasets?: string[];
	extra_gated_prompt?: string;
	extra_gated_fields?: {
		/**
		 * "text" | "checkbox" | "date_picker" | "country" | "ip_location" | { type: "text" | "checkbox" | "date_picker" | "country" | "ip_location" } | { type: "select", options: Array<string | { label: string; value: string; }> } Property
		 */
		[x: string]:
			| "text"
			| "checkbox"
			| "date_picker"
			| "country"
			| "ip_location"
			| { type: "text" | "checkbox" | "date_picker" | "country" | "ip_location" }
			| { type: "select"; options: Array<string | { label: string; value: string }> };
	};
	extra_gated_heading?: string;
	extra_gated_description?: string;
	extra_gated_button_content?: string;
}

declare const EXPAND_KEYS$2: readonly ["private", "downloads", "gated", "likes", "lastModified"];
declare const EXPANDABLE_KEYS$2: readonly ["author", "cardData", "citation", "createdAt", "disabled", "description", "downloads", "downloadsAllTime", "gated", "gitalyUid", "lastModified", "likes", "paperswithcode_id", "private", "sha", "tags"];
interface DatasetEntry {
    id: string;
    name: string;
    private: boolean;
    downloads: number;
    gated: false | "auto" | "manual";
    likes: number;
    updatedAt: Date;
}
declare function listDatasets<const T extends Exclude<(typeof EXPANDABLE_KEYS$2)[number], (typeof EXPAND_KEYS$2)[number]> = never>(params?: {
    search?: {
        /**
         * Will search in the dataset name for matches
         */
        query?: string;
        owner?: string;
        tags?: string[];
    };
    credentials?: Credentials;
    hubUrl?: string;
    additionalFields?: T[];
    /**
     * Set to limit the number of models returned.
     */
    limit?: number;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
}): AsyncGenerator<DatasetEntry & Pick<ApiDatasetInfo, T>>;

interface ListFileEntry {
    type: "file" | "directory" | "unknown";
    size: number;
    path: string;
    oid: string;
    lfs?: {
        oid: string;
        size: number;
        /** Size of the raw pointer file, 100~200 bytes */
        pointerSize: number;
    };
    /**
     * Only fetched if `expand` is set to `true` in the `listFiles` call.
     */
    lastCommit?: {
        date: string;
        id: string;
        title: string;
    };
    /**
     * Only fetched if `expand` is set to `true` in the `listFiles` call.
     */
    security?: unknown;
}
/**
 * List files in a folder. To list ALL files in the directory, call it
 * with {@link params.recursive} set to `true`.
 */
declare function listFiles(params: {
    repo: RepoDesignation;
    /**
     * Do we want to list files in subdirectories?
     */
    recursive?: boolean;
    /**
     * Eg 'data' for listing all files in the 'data' folder. Leave it empty to list all
     * files in the repo.
     */
    path?: string;
    /**
     * Fetch `lastCommit` and `securityStatus` for each file.
     */
    expand?: boolean;
    revision?: string;
    credentials?: Credentials;
    hubUrl?: string;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
}): AsyncGenerator<ListFileEntry>;

interface ApiModelInfo {
	_id: string;
	id: string;
	arxivIds: string[];
	author?: string;
	cardData?: ApiModelMetadata;
	cardError: unknown;
	cardExists?: true;
	config: unknown;
	contributors: Array<{ user: string; _id: string }>;
	disabled: boolean;
	discussionsDisabled: boolean;
	doi?: { id: string; commit: string };
	downloads: number;
	downloadsAllTime: number;
	files: string[];
	gitalyUid: string;
	lastAuthor: { email: string; user?: string };
	lastModified: string; // convert to date
	library_name?: ModelLibraryKey;
	likes: number;
	likesRecent: number;
	private: boolean;
	gated: false | "auto" | "manual";
	sha: string;
	spaces: string[];
	updatedAt: string; // convert to date
	createdAt: string; // convert to date
	pipeline_tag: PipelineType;
	tags: string[];
	"model-index": unknown;
	safetensors?: {
		parameters: Record<string, number>;
		total: number;
	};
	transformersInfo?: TransformersInfo;
}

interface ApiModelIndex {
	name: string;
	results: {
		task: {
			/**
			 * Example: automatic-speech-recognition
Use task id from https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/tasksData.ts
			 */
			type: string;
			/**
			 * Example: Speech Recognition
			 */
			name?: string;
		};
		/**
		 * This will switch to required at some point.
in any case, we need them to link to PWC
		 */
		dataset?: {
			/**
			 * Example: common_voice. Use dataset id from https://hf.co/datasets
			 */
			type: string;
			/**
			 * A pretty name for the dataset. Example: Common Voice zh-CN
Also encode config params into the name if relevant.
			 */
			name: string;
			/**
			 * Optional. The name of the dataset configuration used in `load_dataset()`
			 */
			config?: string;
			/**
			 * Optional. Example: test
			 */
			split?: string;
			/**
			 * Optional. Example: 5503434ddd753f426f4b38109466949a1217c2bb
			 */
			revision?: string;
			args?:
				| string
				| {
						/**
						 * String Property
						 */
						[x: string]: string;
				  };
		};
		metrics: {
			/**
			 * Example: wer. Use metric id from https://hf.co/metrics
			 */
			type: string;
			/**
			 * Required. Example: 20.0 or "20.0 ± 1.2"
			 */
			value: unknown;
			/**
			 * Example: Test WER
			 */
			name?: string;
			/**
			 * Optional. The name of the metric configuration used in `load_metric()`.
			 */
			config?: string;
			args?:
				| string
				| {
						/**
						 * String Property
						 */
						[x: string]: string;
				  };
			/**
			 * [Automatically computed, do not set] Dynamically overriden by huggingface in API calls to indicate if it was verified by Hugging Face.
			 */
			verified?: boolean;
			/**
			 * Generated by Hugging Face to prove the results are valid. <add doc link>
			 */
			verifyToken?: string;
		}[];
		/**
		 * The source for this evaluation result.
		 */
		source?: {
			/**
			 * Example: Open LLM Leaderboard
			 */
			name?: string;
			/**
			 * Example: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard
			 */
			url: string;
		};
	}[];
}

interface ApiWidgetExampleFromModelcard {
	example_title?: string;
	group?: string;
	text?: string;
	src?: string;
	table?: {
		/**
		 * (string | number)[] Property
		 */
		[x: string]: (string | number)[];
	};
	structured_data?: {
		/**
		 * (string | number)[] Property
		 */
		[x: string]: (string | number)[];
	};
	candidate_labels?: string;
	messages?: {
		role: "system" | "user" | "assistant";
		content: string;
	}[];
	multi_class?: boolean;
	source_sentence?: string;
	sentences?: string[];
	parameters?: {
		aggregation_strategy?: string;
		top_k?: number;
		top_p?: number;
		temperature?: number;
		max_new_tokens?: number;
		do_sample?: boolean;
		negative_prompt?: string;
		guidance_scale?: number;
		num_inference_steps?: number;
	};
	output?:
		| {
				label: string;
				score: number;
		  }[]
		| {
				answer: string;
				score: number;
		  }
		| {
				text: string;
		  }
		| {
				url: string;
		  };
}

interface ApiModelMetadata {
	datasets?: string | string[];
	license?: License | License[];
	license_name?: string;
	license_link?: "LICENSE" | "LICENSE.md" | string;
	license_details?: string;
	inference?:
		| boolean
		| {
				parameters?: {
					aggregation_strategy?: string;
					top_k?: number;
					top_p?: number;
					temperature?: number;
					max_new_tokens?: number;
					do_sample?: boolean;
					negative_prompt?: string;
					guidance_scale?: number;
					num_inference_steps?: number;
				};
		  };
	language?: string | string[];
	language_bcp47?: string[];
	language_details?: string;
	tags?: string[];
	pipeline_tag?: string;
	co2_eq_emissions?:
		| number
		| {
				/**
				 * Emissions in grams of CO2
				 */
				emissions: number;
				/**
				 * source of the information, either directly from AutoTrain, code carbon or from a scientific article documenting the model
				 */
				source?: string;
				/**
				 * pre-training or fine-tuning
				 */
				training_type?: string;
				/**
				 * as granular as possible, for instance Quebec, Canada or Brooklyn, NY, USA
				 */
				geographical_location?: string;
				/**
				 * how much compute and what kind, e.g. 8 v100 GPUs
				 */
				hardware_used?: string;
		  };
	library_name?: string;
	thumbnail?: string | null;
	description?: string | null;
	mask_token?: string;
	widget?: ApiWidgetExampleFromModelcard[];
	"model-index"?: ApiModelIndex[];
	finetuned_from?: string;
	base_model?: string | string[];
	instance_prompt?: string | null;
	extra_gated_prompt?: string;
	extra_gated_fields?: {
		/**
		 * "text" | "checkbox" | "date_picker" | "country" | "ip_location" | { type: "text" | "checkbox" | "date_picker" | "country" | "ip_location" } | { type: "select", options: Array<string | { label: string; value: string; }> } Property
		 */
		[x: string]:
			| "text"
			| "checkbox"
			| "date_picker"
			| "country"
			| "ip_location"
			| { type: "text" | "checkbox" | "date_picker" | "country" | "ip_location" }
			| { type: "select"; options: Array<string | { label: string; value: string }> };
	};
	extra_gated_heading?: string;
	extra_gated_description?: string;
	extra_gated_button_content?: string;
}

declare const EXPAND_KEYS$1: readonly ["pipeline_tag", "private", "gated", "downloads", "likes", "lastModified"];
declare const EXPANDABLE_KEYS$1: readonly ["author", "cardData", "config", "createdAt", "disabled", "downloads", "downloadsAllTime", "gated", "gitalyUid", "lastModified", "library_name", "likes", "model-index", "pipeline_tag", "private", "safetensors", "sha", "spaces", "tags", "transformersInfo"];
interface ModelEntry {
    id: string;
    name: string;
    private: boolean;
    gated: false | "auto" | "manual";
    task?: PipelineType;
    likes: number;
    downloads: number;
    updatedAt: Date;
}
declare function listModels<const T extends Exclude<(typeof EXPANDABLE_KEYS$1)[number], (typeof EXPAND_KEYS$1)[number]> = never>(params?: {
    search?: {
        /**
         * Will search in the model name for matches
         */
        query?: string;
        owner?: string;
        task?: PipelineType;
        tags?: string[];
    };
    credentials?: Credentials;
    hubUrl?: string;
    additionalFields?: T[];
    /**
     * Set to limit the number of models returned.
     */
    limit?: number;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
}): AsyncGenerator<ModelEntry & Pick<ApiModelInfo, T>>;

type Color = "red" | "yellow" | "green" | "blue" | "indigo" | "purple" | "pink" | "gray";

interface ApiSpaceInfo {
	_id: string;
	id: string;
	arxivIds?: string[];
	author: string;
	cardExists?: true;
	cardError?: unknown;
	cardData?: unknown;
	contributors?: Array<{ user: string; _id: string }>;
	disabled: boolean;
	discussionsDisabled: boolean;
	duplicationDisabled: boolean;
	gated: false | "auto" | "manual";
	gitalyUid: string;
	lastAuthor: { email: string; user?: string };
	lastModified: string; // date
	likes: number;
	likesRecent: number;
	private: boolean;
	updatedAt: string; // date
	createdAt: string; // date
	tags: string[];
	sha: string;
	subdomain: string;
	title: string;
	emoji: string;
	colorFrom: Color;
	colorTo: Color;
	pinned: boolean;
	siblings: Array<{ rfilename: string }>;
	sdk?: SpaceSdk;
	runtime?: SpaceRuntime;
	models?: string[];
	datasets?: string[];
	originSpace?: { _id: string; authorId: string };
}

declare const EXPAND_KEYS: readonly ["sdk", "likes", "private", "lastModified"];
declare const EXPANDABLE_KEYS: readonly ["author", "cardData", "datasets", "disabled", "gitalyUid", "lastModified", "createdAt", "likes", "private", "runtime", "sdk", "sha", "subdomain", "tags", "models"];
interface SpaceEntry {
    id: string;
    name: string;
    sdk?: SpaceSdk;
    likes: number;
    private: boolean;
    updatedAt: Date;
}
declare function listSpaces<const T extends Exclude<(typeof EXPANDABLE_KEYS)[number], (typeof EXPAND_KEYS)[number]> = never>(params?: {
    search?: {
        /**
         * Will search in the space name for matches
         */
        query?: string;
        owner?: string;
        tags?: string[];
    };
    credentials?: Credentials;
    hubUrl?: string;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
    /**
     * Additional fields to fetch from huggingface.co.
     */
    additionalFields?: T[];
}): AsyncGenerator<SpaceEntry & Pick<ApiSpaceInfo, T>>;

interface OAuthResult {
    accessToken: string;
    accessTokenExpiresAt: Date;
    userInfo: {
        id: string;
        name: string;
        fullname: string;
        email?: string;
        emailVerified?: boolean;
        avatarUrl: string;
        websiteUrl?: string;
        isPro: boolean;
        canPay?: boolean;
        orgs: Array<{
            id: string;
            name: string;
            isEnterprise: boolean;
            canPay?: boolean;
            avatarUrl: string;
            roleInOrg?: string;
        }>;
    };
    /**
     * State passed to the OAuth provider in the original request to the OAuth provider.
     */
    state?: string;
    /**
     * Granted scope
     */
    scope: string;
}
/**
 * To call after the OAuth provider redirects back to the app.
 *
 * There is also a helper function {@link oauthHandleRedirectIfPresent}, which will call `oauthHandleRedirect` if the URL contains an oauth code
 * in the query parameters and return `false` otherwise.
 */
declare function oauthHandleRedirect(opts?: {
    hubUrl?: string;
}): Promise<OAuthResult>;
/**
 * To call after the OAuth provider redirects back to the app.
 *
 * It returns false if the URL does not contain an oauth code in the query parameters, otherwise
 * it calls {@link oauthHandleRedirect}.
 *
 * Depending on your app, you may want to call {@link oauthHandleRedirect} directly instead.
 */
declare function oauthHandleRedirectIfPresent(opts?: {
    hubUrl?: string;
}): Promise<OAuthResult | false>;

/**
 * Use "Sign in with Hub" to authenticate a user, and get oauth user info / access token.
 *
 * Returns an url to redirect to. After the user is redirected back to your app, call `oauthHandleRedirect` to get the oauth user info / access token.
 *
 * When called from inside a static Space with OAuth enabled, it will load the config from the space, otherwise you need to at least specify
 * the client ID of your OAuth App.
 *
 * @example
 * ```ts
 * import { oauthLoginUrl, oauthHandleRedirectIfPresent } from "@huggingface/hub";
 *
 * const oauthResult = await oauthHandleRedirectIfPresent();
 *
 * if (!oauthResult) {
 *   // If the user is not logged in, redirect to the login page
 *   window.location.href = await oauthLoginUrl();
 * }
 *
 * // You can use oauthResult.accessToken, oauthResult.accessTokenExpiresAt and oauthResult.userInfo
 * console.log(oauthResult);
 * ```
 *
 * (Theoretically, this function could be used to authenticate a user for any OAuth provider supporting PKCE and OpenID Connect by changing `hubUrl`,
 * but it is currently only tested with the Hugging Face Hub.)
 */
declare function oauthLoginUrl(opts?: {
    /**
     * OAuth client ID.
     *
     * For static Spaces, you can omit this and it will be loaded from the Space config, as long as `hf_oauth: true` is present in the README.md's metadata.
     * For other Spaces, it is available to the backend in the OAUTH_CLIENT_ID environment variable, as long as `hf_oauth: true` is present in the README.md's metadata.
     *
     * You can also create a Developer Application at https://huggingface.co/settings/connected-applications and use its client ID.
     */
    clientId?: string;
    hubUrl?: string;
    /**
     * OAuth scope, a list of space separate scopes.
     *
     * For static Spaces, you can omit this and it will be loaded from the Space config, as long as `hf_oauth: true` is present in the README.md's metadata.
     * For other Spaces, it is available to the backend in the OAUTH_SCOPES environment variable, as long as `hf_oauth: true` is present in the README.md's metadata.
     *
     * Defaults to "openid profile".
     *
     * You can also create a Developer Application at https://huggingface.co/settings/connected-applications and use its scopes.
     *
     * See https://huggingface.co/docs/hub/oauth for a list of available scopes.
     */
    scopes?: string;
    /**
     * Redirect URI, defaults to the current URL.
     *
     * For Spaces, any URL within the Space is allowed.
     *
     * For Developer Applications, you can add any URL you want to the list of allowed redirect URIs at https://huggingface.co/settings/connected-applications.
     */
    redirectUrl?: string;
    /**
     * State to pass to the OAuth provider, which will be returned in the call to `oauthLogin` after the redirect.
     */
    state?: string;
}): Promise<string>;

/**
Matches a JSON object.

This type can be useful to enforce some input to be JSON-compatible or as a super-type to be extended from. Don't use this as a direct return type as the user would have to double-cast it: `jsonObject as unknown as CustomResponse`. Instead, you could extend your CustomResponse type from it to ensure your type only uses JSON-compatible types: `interface CustomResponse extends JsonObject { … }`.

@category JSON
*/
type JsonObject = {[Key in string]: JsonValue} & {[Key in string]?: JsonValue | undefined};

/**
Matches a JSON array.

@category JSON
*/
type JsonArray = JsonValue[] | readonly JsonValue[];

/**
Matches any valid JSON primitive value.

@category JSON
*/
type JsonPrimitive = string | number | boolean | null;

/**
Matches any valid JSON value.

@see `Jsonify` if you need to transform a type to one that is assignable to `JsonValue`.

@category JSON
*/
type JsonValue = JsonPrimitive | JsonObject | JsonArray;

declare global {
	// eslint-disable-next-line @typescript-eslint/consistent-type-definitions -- It has to be an `interface` so that it can be merged.
	interface SymbolConstructor {
		readonly observable: symbol;
	}
}

/**
Returns a boolean for whether the two given types are equal.

@link https://github.com/microsoft/TypeScript/issues/27024#issuecomment-421529650
@link https://stackoverflow.com/questions/68961864/how-does-the-equals-work-in-typescript/68963796#68963796

Use-cases:
- If you want to make a conditional branch based on the result of a comparison of two types.

@example
```
import type {IsEqual} from 'type-fest';

// This type returns a boolean for whether the given array includes the given item.
// `IsEqual` is used to compare the given array at position 0 and the given item and then return true if they are equal.
type Includes<Value extends readonly any[], Item> =
	Value extends readonly [Value[0], ...infer rest]
		? IsEqual<Value[0], Item> extends true
			? true
			: Includes<rest, Item>
		: false;
```

@category Type Guard
@category Utilities
*/
type IsEqual<A, B> =
	(<G>() => G extends A ? 1 : 2) extends
	(<G>() => G extends B ? 1 : 2)
		? true
		: false;

/**
Filter out keys from an object.

Returns `never` if `Exclude` is strictly equal to `Key`.
Returns `never` if `Key` extends `Exclude`.
Returns `Key` otherwise.

@example
```
type Filtered = Filter<'foo', 'foo'>;
//=> never
```

@example
```
type Filtered = Filter<'bar', string>;
//=> never
```

@example
```
type Filtered = Filter<'bar', 'foo'>;
//=> 'bar'
```

@see {Except}
*/
type Filter<KeyType, ExcludeType> = IsEqual<KeyType, ExcludeType> extends true ? never : (KeyType extends ExcludeType ? never : KeyType);

type ExceptOptions = {
	/**
	Disallow assigning non-specified properties.

	Note that any omitted properties in the resulting type will be present in autocomplete as `undefined`.

	@default false
	*/
	requireExactProps?: boolean;
};

/**
Create a type from an object type without certain keys.

We recommend setting the `requireExactProps` option to `true`.

This type is a stricter version of [`Omit`](https://www.typescriptlang.org/docs/handbook/release-notes/typescript-3-5.html#the-omit-helper-type). The `Omit` type does not restrict the omitted keys to be keys present on the given type, while `Except` does. The benefits of a stricter type are avoiding typos and allowing the compiler to pick up on rename refactors automatically.

This type was proposed to the TypeScript team, which declined it, saying they prefer that libraries implement stricter versions of the built-in types ([microsoft/TypeScript#30825](https://github.com/microsoft/TypeScript/issues/30825#issuecomment-523668235)).

@example
```
import type {Except} from 'type-fest';

type Foo = {
	a: number;
	b: string;
};

type FooWithoutA = Except<Foo, 'a'>;
//=> {b: string}

const fooWithoutA: FooWithoutA = {a: 1, b: '2'};
//=> errors: 'a' does not exist in type '{ b: string; }'

type FooWithoutB = Except<Foo, 'b', {requireExactProps: true}>;
//=> {a: number} & Partial<Record<"b", never>>

const fooWithoutB: FooWithoutB = {a: 1, b: '2'};
//=> errors at 'b': Type 'string' is not assignable to type 'undefined'.
```

@category Object
*/
type Except<ObjectType, KeysType extends keyof ObjectType, Options extends ExceptOptions = {requireExactProps: false}> = {
	[KeyType in keyof ObjectType as Filter<KeyType, KeysType>]: ObjectType[KeyType];
} & (Options['requireExactProps'] extends true
	? Partial<Record<KeysType, never>>
	: {});

/**
Useful to flatten the type output to improve type hints shown in editors. And also to transform an interface into a type to aide with assignability.

@example
```
import type {Simplify} from 'type-fest';

type PositionProps = {
	top: number;
	left: number;
};

type SizeProps = {
	width: number;
	height: number;
};

// In your editor, hovering over `Props` will show a flattened object with all the properties.
type Props = Simplify<PositionProps & SizeProps>;
```

Sometimes it is desired to pass a value as a function argument that has a different type. At first inspection it may seem assignable, and then you discover it is not because the `value`'s type definition was defined as an interface. In the following example, `fn` requires an argument of type `Record<string, unknown>`. If the value is defined as a literal, then it is assignable. And if the `value` is defined as type using the `Simplify` utility the value is assignable.  But if the `value` is defined as an interface, it is not assignable because the interface is not sealed and elsewhere a non-string property could be added to the interface.

If the type definition must be an interface (perhaps it was defined in a third-party npm package), then the `value` can be defined as `const value: Simplify<SomeInterface> = ...`. Then `value` will be assignable to the `fn` argument.  Or the `value` can be cast as `Simplify<SomeInterface>` if you can't re-declare the `value`.

@example
```
import type {Simplify} from 'type-fest';

interface SomeInterface {
	foo: number;
	bar?: string;
	baz: number | undefined;
}

type SomeType = {
	foo: number;
	bar?: string;
	baz: number | undefined;
};

const literal = {foo: 123, bar: 'hello', baz: 456};
const someType: SomeType = literal;
const someInterface: SomeInterface = literal;

function fn(object: Record<string, unknown>): void {}

fn(literal); // Good: literal object type is sealed
fn(someType); // Good: type is sealed
fn(someInterface); // Error: Index signature for type 'string' is missing in type 'someInterface'. Because `interface` can be re-opened
fn(someInterface as Simplify<SomeInterface>); // Good: transform an `interface` into a `type`
```

@link https://github.com/microsoft/TypeScript/issues/15300

@category Object
*/
type Simplify<T> = {[KeyType in keyof T]: T[KeyType]} & {};

/**
Create a type that makes the given keys required. The remaining keys are kept as is. The sister of the `SetOptional` type.

Use-case: You want to define a single model where the only thing that changes is whether or not some of the keys are required.

@example
```
import type {SetRequired} from 'type-fest';

type Foo = {
	a?: number;
	b: string;
	c?: boolean;
}

type SomeRequired = SetRequired<Foo, 'b' | 'c'>;
// type SomeRequired = {
// 	a?: number;
// 	b: string; // Was already required and still is.
// 	c: boolean; // Is now required.
// }
```

@category Object
*/
type SetRequired<BaseType, Keys extends keyof BaseType> =
	Simplify<
	// Pick just the keys that are optional from the base type.
	Except<BaseType, Keys> &
	// Pick the keys that should be required from the base type and make them required.
	Required<Pick<BaseType, Keys>>
	>;

declare const SAFETENSORS_FILE = "model.safetensors";
declare const SAFETENSORS_INDEX_FILE = "model.safetensors.index.json";
declare const RE_SAFETENSORS_FILE: RegExp;
declare const RE_SAFETENSORS_INDEX_FILE: RegExp;
declare const RE_SAFETENSORS_SHARD_FILE: RegExp;
interface SafetensorsShardFileInfo {
    prefix: string;
    basePrefix: string;
    shard: string;
    total: string;
}
declare function parseSafetensorsShardFilename(filename: string): SafetensorsShardFileInfo | null;
type FileName = string;
type TensorName = string;
type Dtype = "F64" | "F32" | "F16" | "BF16" | "I64" | "I32" | "I16" | "I8" | "U8" | "BOOL";
interface TensorInfo {
    dtype: Dtype;
    shape: number[];
    data_offsets: [number, number];
}
type SafetensorsFileHeader = Record<TensorName, TensorInfo> & {
    __metadata__: Record<string, string>;
};
interface SafetensorsIndexJson {
    dtype?: string;
    metadata?: Record<string, string>;
    weight_map: Record<TensorName, FileName>;
}
type SafetensorsShardedHeaders = Record<FileName, SafetensorsFileHeader>;
type SafetensorsParseFromRepo = {
    sharded: false;
    header: SafetensorsFileHeader;
    parameterCount?: Partial<Record<Dtype, number>>;
} | {
    sharded: true;
    index: SafetensorsIndexJson;
    headers: SafetensorsShardedHeaders;
    parameterCount?: Partial<Record<Dtype, number>>;
};
/**
 * Analyze model.safetensors.index.json or model.safetensors from a model hosted
 * on Hugging Face using smart range requests to extract its metadata.
 */
declare function parseSafetensorsMetadata(params: {
    /** Only models are supported */
    repo: RepoDesignation;
    /**
     * Relative file path to safetensors file inside `repo`. Defaults to `SAFETENSORS_FILE` or `SAFETENSORS_INDEX_FILE` (whichever one exists).
     */
    path?: string;
    /**
     * Will include SafetensorsParseFromRepo["parameterCount"], an object containing the number of parameters for each DType
     *
     * @default false
     */
    computeParametersCount: true;
    hubUrl?: string;
    credentials?: Credentials;
    revision?: string;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
}): Promise<SetRequired<SafetensorsParseFromRepo, "parameterCount">>;
declare function parseSafetensorsMetadata(params: {
    /** Only models are supported */
    repo: RepoDesignation;
    /**
     * Will include SafetensorsParseFromRepo["parameterCount"], an object containing the number of parameters for each DType
     *
     * @default false
     */
    path?: string;
    computeParametersCount?: boolean;
    hubUrl?: string;
    credentials?: Credentials;
    revision?: string;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
}): Promise<SafetensorsParseFromRepo>;

declare function uploadFile(params: {
    credentials?: Credentials;
    repo: CommitParams["repo"];
    file: URL | File | {
        path: string;
        content: ContentSource;
    };
    commitTitle?: CommitParams["title"];
    commitDescription?: CommitParams["description"];
    hubUrl?: CommitParams["hubUrl"];
    branch?: CommitParams["branch"];
    isPullRequest?: CommitParams["isPullRequest"];
    parentCommit?: CommitParams["parentCommit"];
    fetch?: CommitParams["fetch"];
    useWebWorkers?: CommitParams["useWebWorkers"];
    abortSignal?: CommitParams["abortSignal"];
}): Promise<CommitOutput>;

declare function uploadFiles(params: {
    credentials?: CommitParams["credentials"];
    repo: CommitParams["repo"];
    files: Array<URL | File | {
        path: string;
        content: ContentSource;
    }>;
    commitTitle?: CommitParams["title"];
    commitDescription?: CommitParams["description"];
    hubUrl?: CommitParams["hubUrl"];
    branch?: CommitParams["branch"];
    isPullRequest?: CommitParams["isPullRequest"];
    parentCommit?: CommitParams["parentCommit"];
    fetch?: CommitParams["fetch"];
    useWebWorkers?: CommitParams["useWebWorkers"];
    abortSignal?: CommitParams["abortSignal"];
}): Promise<CommitOutput>;

/**
 * Uploads with progress
 *
 * Needs XMLHttpRequest to be available for progress events for uploads
 * Set useWebWorkers to true in order to have progress events for hashing
 */
declare function uploadFilesWithProgress(params: {
    credentials?: CommitParams["credentials"];
    repo: CommitParams["repo"];
    files: Array<URL | File | {
        path: string;
        content: ContentSource;
    }>;
    commitTitle?: CommitParams["title"];
    commitDescription?: CommitParams["description"];
    hubUrl?: CommitParams["hubUrl"];
    branch?: CommitParams["branch"];
    isPullRequest?: CommitParams["isPullRequest"];
    parentCommit?: CommitParams["parentCommit"];
    abortSignal?: CommitParams["abortSignal"];
    /**
     * Set this to true in order to have progress events for hashing
     */
    useWebWorkers?: CommitParams["useWebWorkers"];
}): AsyncGenerator<CommitProgressEvent, CommitOutput>;

interface WhoAmIUser {
    /** Unique ID persistent across renames */
    id: string;
    type: "user";
    email: string;
    emailVerified: boolean;
    isPro: boolean;
    orgs: WhoAmIOrg[];
    name: string;
    fullname: string;
    canPay: boolean;
    avatarUrl: string;
    /**
     * Unix timestamp in seconds
     */
    periodEnd: number | null;
}
interface WhoAmIOrg {
    /** Unique ID persistent across renames */
    id: string;
    type: "org";
    name: string;
    fullname: string;
    email: string | null;
    canPay: boolean;
    avatarUrl: string;
    /**
     * Unix timestamp in seconds
     */
    periodEnd: number | null;
}
interface WhoAmIApp {
    id: string;
    type: "app";
    name: string;
    scope?: {
        entities: string[];
        role: "admin" | "write" | "contributor" | "read";
    };
}
type WhoAmI = WhoAmIApp | WhoAmIOrg | WhoAmIUser;
interface AuthInfo {
    type: AuthType;
    accessToken?: {
        displayName: string;
        expiration?: Date;
        role: AccessTokenRole;
    };
    expiresAt?: Date;
}
declare function whoAmI(params: {
    credentials: Credentials;
    hubUrl?: string;
    /**
     * Custom fetch function to use instead of the default one, for example to use a proxy or edit headers.
     */
    fetch?: typeof fetch;
}): Promise<WhoAmI & {
    auth: AuthInfo;
}>;

/**
 * Error thrown when an API call to the Hugging Face Hub fails.
 */
declare class HubApiError extends Error {
    statusCode: number;
    url: string;
    requestId?: string;
    data?: JsonObject;
    constructor(url: string, statusCode: number, requestId?: string, message?: string);
}
declare class InvalidApiResponseFormatError extends Error {
}

export { AccessToken, AccessTokenRole, AuthInfo, AuthType, CommitData, CommitDeletedEntry, CommitFile, CommitOperation, CommitOutput, CommitParams, CommitProgressEvent, ContentSource, Credentials, DatasetEntry, Dtype, FileDownloadInfoOutput, HubApiError, InvalidApiResponseFormatError, ListFileEntry, ModelEntry, OAuthResult, PipelineType, RE_SAFETENSORS_FILE, RE_SAFETENSORS_INDEX_FILE, RE_SAFETENSORS_SHARD_FILE, RepoDesignation, RepoFullName, RepoId, RepoType, SAFETENSORS_FILE, SAFETENSORS_INDEX_FILE, SafetensorsFileHeader, SafetensorsIndexJson, SafetensorsParseFromRepo, SafetensorsShardFileInfo, SafetensorsShardedHeaders, SpaceEntry, SpaceHardwareFlavor, SpaceResourceConfig, SpaceResourceRequirement, SpaceRuntime, SpaceSdk, SpaceStage, TensorInfo, TensorName, WhoAmI, WhoAmIApp, WhoAmIOrg, WhoAmIUser, commit, commitIter, countCommits, createRepo, deleteFile, deleteFiles, deleteRepo, downloadFile, fileDownloadInfo, fileExists, listCommits, listDatasets, listFiles, listModels, listSpaces, oauthHandleRedirect, oauthHandleRedirectIfPresent, oauthLoginUrl, parseSafetensorsMetadata, parseSafetensorsShardFilename, uploadFile, uploadFiles, uploadFilesWithProgress, whoAmI };
